# --- Predict win probabilities ---
p_first_in_num <- 0.6481901
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in_num + p_win_second * (1 - p_first_in_num)
)
# --- Find optimal serve speed ---
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
# --- Plot ---
library(ggplot2)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(x = Speed_MPH, y = p_win_total, label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, hjust = 0.5, size = 4, color = "red"
) +
labs(
title = "Serve Speed vs. Overall Point Win Probability",
x = "Serve Speed (MPH)",
y = "P(win)",
caption = "Holding serve placement, point importance, server double fault percentage, and opponent quality constant"
) +
theme_minimal()
p_win_second_constant <- mean(predict(model_second, type = "response"), na.rm = TRUE)
grid_data <- tibble(
Speed_MPH = speed_seq,
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# Predict P(first serve in) and P(win | first serve in)
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = p_win_second_constant,
p_win_total = p_win_first * p_first_in_num + p_win_second * (1 - p_first_in_num)
)
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, size = 4, color = "red"
) +
labs(
title = "Optimal First Serve Speed (Holding P(win | Second Serve) Constant)",
x = "First Serve Speed (MPH)",
y = "Overall P(win)",
caption = "Based on modeled accuracy and win probability for first serve; constant second serve win rate"
) +
theme_minimal()
# --- Clear Environment & Load Libraries ---
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load Data ---
subset_m <- fread("out_data/scaled/wimbledon_subset_f_training.csv")
names(subset_m)
# --- Step 1: Filter relevant rows ---
# ServeNumber == 1 means first serve was in, ServeNumber == 2 means it was out
# We only care about first serve attempts
df <- subset_m %>%
filter(ServeNumber %in% c(1, 2)) %>%
mutate(first_serve_in = ifelse(ServeNumber == 1, 1, 0))
# --- Step 2: Compute first serve stats per match per server ---
match_player_stats <- df %>%
group_by(match_id, ServerName) %>%
summarise(
n_points = n(),
n_first_in = sum(first_serve_in),
.groups = "drop"
) %>%
mutate(first_in_rate = n_first_in / n_points)
# --- Step 3: Compute per-player averages across matches ---
player_summary <- match_player_stats %>%
group_by(ServerName) %>%
summarise(
n_matches = n(),
avg_first_in_rate = mean(first_in_rate),
.groups = "drop"
)
# --- Step 4: Compute weighted average across all players ---
overall_weighted_avg <- player_summary %>%
mutate(weight = n_matches / sum(n_matches)) %>%
summarise(prob_first_serve_in = sum(avg_first_in_rate * weight)) %>%
pull(prob_first_serve_in)
overall_weighted_avg
# --- Most common ServeWidth and ServeDepth ---
mode_width <- df %>% count(ServeWidth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeWidth)
mode_depth <- df %>% count(ServeDepth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeDepth)
# --- Modeling datasets ---
first_serve_df <- df %>% filter(ServeNumber == 1)
second_serve_df <- df %>% filter(ServeNumber == 2)
# --- Fit logistic models ---
predictors <- c("Speed_MPH", "ServeWidth", "ServeDepth", "importance_z", "df_pct_server_z", "p_server_beats_returner_z")
formula <- as.formula(paste("serving_player_won ~", paste(predictors, collapse = " + ")))
model_first <- glm(formula, data = first_serve_df, family = "binomial")
model_second <- glm(formula, data = second_serve_df, family = "binomial")
# --- Fixed values for other predictors (use median z-values) ---
median_vals <- df %>%
summarise(across(all_of(predictors[4:6]), median, na.rm = TRUE))  # skip speed_ratio_z for now
# --- Create speed range and compute z-scores ---
speed_seq <- seq(80, 145, by = 1)
speed_mean <- mean(df$Speed_MPH, na.rm = TRUE)
speed_sd <- sd(df$Speed_MPH, na.rm = TRUE)
speed_z <- (speed_seq - speed_mean) / speed_sd
# --- Construct data for prediction ---
grid_data <- tibble(
Speed_MPH = speed_seq,
speed_ratio_z = (speed_seq / mean(df$Speed_MPH, na.rm = TRUE) - 1),  # use ratio to player average
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# --- Predict win probabilities ---
p_first_in_num <- 0.6481901
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in_num + p_win_second * (1 - p_first_in_num)
)
# --- Find optimal serve speed ---
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
# --- Plot ---
library(ggplot2)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(x = Speed_MPH, y = p_win_total, label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, hjust = 0.5, size = 4, color = "red"
) +
labs(
title = "Serve Speed vs. Overall Point Win Probability",
x = "Serve Speed (MPH)",
y = "P(win)",
caption = "Holding serve placement, point importance, server double fault percentage, and opponent quality constant"
) +
theme_minimal()
######################
# keep P(win | second serve in) constant
p_win_second_constant <- mean(predict(model_second, type = "response"), na.rm = TRUE)
grid_data <- tibble(
Speed_MPH = speed_seq,
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# Predict P(first serve in) and P(win | first serve in)
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = p_win_second_constant,
p_win_total = p_win_first * p_first_in_num + p_win_second * (1 - p_first_in_num)
)
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, size = 4, color = "red"
) +
labs(
title = "Optimal First Serve Speed (Holding P(win | Second Serve) Constant)",
x = "First Serve Speed (MPH)",
y = "Overall P(win)",
caption = "Based on modeled accuracy and win probability for first serve; constant second serve win rate"
) +
theme_minimal()
summary(df$speed_ratio)
# --- Clear Environment & Load Libraries ---
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load Data ---
subset_m <- fread("out_data/scaled/wimbledon_subset_f_training.csv")
names(subset_m)
analyze_first_serve_strategy <- function(
df,
speed_var = "Speed_MPH",  # or "speed_ratio"
p_first_in_num = NULL     # optional override; will compute if NULL
) {
# --- Step 1: Filter relevant rows and compute first serve in ---
df <- df %>%
filter(ServeNumber %in% c(1, 2)) %>%
mutate(first_serve_in = ifelse(ServeNumber == 1, 1, 0))
# --- Step 2: First serve stats per match per server ---
match_player_stats <- df %>%
group_by(match_id, ServerName) %>%
summarise(
n_points = n(),
n_first_in = sum(first_serve_in),
.groups = "drop"
) %>%
mutate(first_in_rate = n_first_in / n_points)
# --- Step 3: Per-player averages across matches ---
player_summary <- match_player_stats %>%
group_by(ServerName) %>%
summarise(
n_matches = n(),
avg_first_in_rate = mean(first_in_rate),
.groups = "drop"
)
# --- Step 4: Compute weighted average ---
if (is.null(p_first_in_num)) {
p_first_in_num <- player_summary %>%
mutate(weight = n_matches / sum(n_matches)) %>%
summarise(prob_first_serve_in = sum(avg_first_in_rate * weight)) %>%
pull(prob_first_serve_in)
}
cat("Weighted average P(first serve in):", round(p_first_in_num, 4), "\n\n")
# --- Modes for categorical predictors ---
mode_width <- df %>% count(ServeWidth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeWidth)
mode_depth <- df %>% count(ServeDepth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeDepth)
# --- Modeling datasets ---
first_serve_df <- df %>% filter(ServeNumber == 1)
second_serve_df <- df %>% filter(ServeNumber == 2)
# --- Fit logistic models ---
predictors <- c(speed_var, "ServeWidth", "ServeDepth", "importance_z", "df_pct_server_z", "p_server_beats_returner_z")
formula <- as.formula(paste("serving_player_won ~", paste(predictors, collapse = " + ")))
model_first <- glm(formula, data = first_serve_df, family = "binomial")
model_second <- glm(formula, data = second_serve_df, family = "binomial")
# --- Median z-values ---
median_vals <- df %>%
summarise(across(c("importance_z", "df_pct_server_z", "p_server_beats_returner_z"), median, na.rm = TRUE))
# --- Define speed sequence and z-scores ---
speed_seq <- if (speed_var == "Speed_MPH") {
seq(80, 145, by = 1)
} else {
seq(0.55, 1.25, by = 0.01)
}
speed_mean <- mean(df[[speed_var]], na.rm = TRUE)
speed_sd <- sd(df[[speed_var]], na.rm = TRUE)
speed_z <- (speed_seq - speed_mean) / speed_sd
# --- Prepare grid data for predictions ---
grid_data <- tibble(
!!speed_var := speed_seq,
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# --- Predict full P(win) with modeled second serve ---
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in_num + p_win_second * (1 - p_first_in_num)
)
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
p1 <- ggplot(grid_data, aes_string(x = speed_var, y = "p_win_total")) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes_string(x = speed_var, y = "p_win_total"), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes_string(label = sprintf("paste('Optimal:', round(%s), '%s')", speed_var, ifelse(speed_var == "Speed_MPH", " MPH", ""))),
vjust = -1.2, size = 4, color = "red"
) +
labs(
title = "P(win) vs. Serve Speed (Full Model)",
x = ifelse(speed_var == "Speed_MPH", "Serve Speed (MPH)", "Serve Speed Ratio"),
y = "P(win)"
) +
theme_minimal()
print(p1)
# --- Predict with constant P(win | second serve) ---
p_win_second_constant <- mean(predict(model_second, type = "response"), na.rm = TRUE)
grid_data <- tibble(
!!speed_var := speed_seq,
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = p_win_second_constant,
p_win_total = p_win_first * p_first_in_num + p_win_second * (1 - p_first_in_num)
)
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
p2 <- ggplot(grid_data, aes_string(x = speed_var, y = "p_win_total")) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes_string(x = speed_var, y = "p_win_total"), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes_string(label = sprintf("paste('Optimal:', round(%s), '%s')", speed_var, ifelse(speed_var == "Speed_MPH", " MPH", ""))),
vjust = -1.2, size = 4, color = "red"
) +
labs(
title = "P(win) vs. Serve Speed (Constant 2nd Serve Win Rate)",
x = ifelse(speed_var == "Speed_MPH", "Serve Speed (MPH)", "Serve Speed Ratio"),
y = "P(win)"
) +
theme_minimal()
print(p2)
invisible(NULL)
}
analyze_first_serve_strategy(df, speed_var = "Speed_MPH")
analyze_first_serve_strategy(subset_m, speed_var = "Speed_MPH")
analyze_first_serve_strategy(subset_m, speed_var = "speed_ratio")
View(subset_m)
# --- Clear environment and load libraries ---
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load data ---
df <- fread("out_data/scaled/wimbledon_subset_m_training.csv")
# --- Filter to only first serve attempts ---
df <- df %>%
filter(ServeNumber %in% c(1, 2)) %>%
mutate(first_serve_in = ifelse(ServeNumber == 1, 1, 0))
# --- Subset first and second serves ---
first_serve_df <- df %>% filter(ServeNumber == 1)
second_serve_df <- df %>% filter(ServeNumber == 2)
# --- Step 1: Compute player-level summaries ---
# First serve win %, in %, and average speed
first_summary <- first_serve_df %>%
group_by(ServerName) %>%
summarise(
n_first = n(),
avg_speed_mph = mean(Speed_MPH, na.rm = TRUE),
first_win_pct = mean(serving_player_won, na.rm = TRUE),
.groups = "drop"
)
# First serve in rate (based on both ServeNumber == 1 and 2)
player_attempts <- df %>%
group_by(ServerName) %>%
summarise(
n_total = n(),
n_in = sum(first_serve_in),
first_in_pct = n_in / n_total,
.groups = "drop"
)
# Second serve win rate
second_summary <- second_serve_df %>%
group_by(ServerName) %>%
summarise(
second_win_pct = mean(serving_player_won, na.rm = TRUE),
.groups = "drop"
)
# Combine all summaries
player_level <- first_summary %>%
inner_join(player_attempts, by = "ServerName") %>%
inner_join(second_summary, by = "ServerName") %>%
mutate(
est_overall_win = first_in_pct * first_win_pct + (1 - first_in_pct) * second_win_pct
)
# --- Print summary ---
cat("Summary of player-level first serve strategy dataset:\n")
print(head(player_level))
names(df)
View(df)
player_level
# Combine all summaries
player_level <- first_summary %>%
inner_join(player_attempts, by = "ServerName") %>%
inner_join(second_summary, by = "ServerName") %>%
mutate(
est_overall_win = first_in_pct * first_win_pct + (1 - first_in_pct) * second_win_pct
)
# --- Step 2: Plot relationships ---
# First serve speed vs in-rate
p1 <- ggplot(player_level, aes(x = avg_speed_mph, y = first_in_pct)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "blue") +
labs(
title = "First Serve Speed vs. First Serve In Percentage",
x = "Average 1st Serve Speed (MPH)",
y = "First Serve In %"
) +
theme_minimal()
# First serve speed vs win rate (when in)
p2 <- ggplot(player_level, aes(x = avg_speed_mph, y = first_win_pct)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "darkgreen") +
labs(
title = "First Serve Speed vs. Win % (on 1st Serve In)",
x = "Average 1st Serve Speed (MPH)",
y = "Win % on 1st Serve In"
) +
theme_minimal()
# First serve speed vs estimated overall win %
p3 <- ggplot(player_level, aes(x = avg_speed_mph, y = est_overall_win)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "purple") +
labs(
title = "First Serve Speed vs. Estimated Overall Win %",
x = "Average 1st Serve Speed (MPH)",
y = "Estimated Win %"
) +
theme_minimal()
# --- Show plots ---
print(p1)
print(p2)
print(p3)
# --- Optional: Identify speed that maximizes estimated overall win ---
opt_row <- player_level %>%
filter(est_overall_win == max(est_overall_win)) %>%
slice(1)
cat("\nPlayer with optimal estimated overall win rate:\n")
print(opt_row %>% select(ServerName, avg_speed_mph, est_overall_win))
# --- Show plots ---
print(p1)
print(p3)
# --- Clear environment and load libraries ---
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load data ---
df <- fread("out_data/scaled/wimbledon_subset_m_training.csv")
names(df)
# --- Filter to only first serve attempts ---
df <- df %>%
filter(ServeNumber %in% c(1, 2)) %>%
mutate(first_serve_in = ifelse(ServeNumber == 1, 1, 0))
# --- Subset first and second serves ---
first_serve_df <- df %>% filter(ServeNumber == 1)
second_serve_df <- df %>% filter(ServeNumber == 2)
# --- Step 1: Compute player-level summaries ---
# First serve win %, in %, and average speed
first_summary <- first_serve_df %>%
group_by(ServerName) %>%
summarise(
n_first = n(),
avg_speed_mph = mean(Speed_MPH, na.rm = TRUE),
first_win_pct = mean(serving_player_won, na.rm = TRUE),
.groups = "drop"
)
# First serve in rate (based on both ServeNumber == 1 and 2)
player_attempts <- df %>%
group_by(ServerName) %>%
summarise(
n_total = n(),
n_in = sum(first_serve_in),
first_in_pct = n_in / n_total,
.groups = "drop"
)
# Second serve win rate
second_summary <- second_serve_df %>%
group_by(ServerName) %>%
summarise(
second_win_pct = mean(serving_player_won, na.rm = TRUE),
.groups = "drop"
)
# Combine all summaries
player_level <- first_summary %>%
inner_join(player_attempts, by = "ServerName") %>%
inner_join(second_summary, by = "ServerName") %>%
mutate(
est_overall_win = first_in_pct * first_win_pct + (1 - first_in_pct) * second_win_pct
)
# --- Step 2: Plot relationships ---
# First serve speed vs in-rate
p1 <- ggplot(player_level, aes(x = avg_speed_mph, y = first_in_pct)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "blue") +
labs(
title = "First Serve Speed vs. First Serve In Percentage",
x = "Average 1st Serve Speed (MPH)",
y = "First Serve In %"
) +
theme_minimal()
# First serve speed vs win rate (when in)
p2 <- ggplot(player_level, aes(x = avg_speed_mph, y = first_win_pct)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "darkgreen") +
labs(
title = "First Serve Speed vs. Win % (on 1st Serve In)",
x = "Average 1st Serve Speed (MPH)",
y = "Win % on 1st Serve In"
) +
theme_minimal()
# First serve speed vs estimated overall win %
p3 <- ggplot(player_level, aes(x = avg_speed_mph, y = est_overall_win)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "purple") +
labs(
title = "First Serve Speed vs. Estimated Overall Win %",
x = "Average 1st Serve Speed (MPH)",
y = "Estimated Win %"
) +
theme_minimal()
# --- Show plots ---
print(p1)
print(p2)
print(p3)
# --- Optional: Identify speed that maximizes estimated overall win ---
opt_row <- player_level %>%
filter(est_overall_win == max(est_overall_win)) %>%
slice(1)
cat("\nPlayer with optimal estimated overall win rate:\n")
print(opt_row %>% select(ServerName, avg_speed_mph, est_overall_win))
names(df)
