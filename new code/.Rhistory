test_sub[, (v) := factor(get(v), levels = levels(train_sub[[v]]))]
## response as factor
train_sub[, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
test_sub [, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
for (speed_var in c("Speed_MPH_z", "speed_ratio_z")) {
vars_num <- c(base_num, speed_var)
## modelling frames
train_dat <- train_sub[, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
test_dat  <- test_sub [, c(vars_num, vars_fact), with = FALSE]
## -------- 3-fold tune on ≤10 000 rows ---------------------------
n_tune   <- min(10000, nrow(train_dat))
tune_dat <- train_dat[sample(nrow(train_dat), n_tune)]
tuned <- tune(
svm,
serving_player_won ~ .,
data        = tune_dat,
kernel      = "linear",
ranges      = grid_small,
tunecontrol = tune.control(cross = 3)
)
bp <- tuned$best.parameters
## -------- Fit best model on full subset -------------------------
fit <- svm(
serving_player_won ~ .,
data        = train_dat,
kernel      = "linear",
cost        = bp$cost,
gamma       = bp$gamma,
probability = TRUE
)
## -------- Evaluate on test subset -------------------------------
pred_class <- predict(fit, newdata = test_dat)
pred_prob  <- attr(predict(fit, newdata = test_dat, probability = TRUE),
"probabilities")[, "1"]
acc <- mean(pred_class == test_sub$serving_player_won)
ll  <- fast_logloss(test_sub$serving_player_won, pred_prob)
## -------- Store result ------------------------------------------
results[[length(results) + 1]] <- list(
gender         = g,
serve_number   = serve,
speed_variable = speed_var,
test_accuracy  = acc,
log_loss       = ll
)
}
}
}
############################################################
## 4.  Results data-frame
############################################################
results_df <- bind_rows(results) %>%
arrange(gender, serve_number, speed_variable)
print(results_df)
# Save results to CSV
write.csv(results_df, "svm_results_usopen.csv", row.names = FALSE)
############################################################
## nn_usopen.R ― Neural-network benchmark for US-Open data
##  - Loops over gender, serve #, and speed variable
##  - 3-fold CV grid-search for (size, decay)
##  - Computes test accuracy & log loss
############################################################
rm(list=ls())
## 0.  Packages & helpers ----------------------------------------------
library(data.table)
library(tidyverse)   # dplyr, purrr, tibble, …
library(nnet)        # feed-forward neural nets
library(tibble)
library(purrr)
## Fast log-loss (binary)
fast_logloss <- function(truth, prob1, eps = 1e-15) {
prob1 <- pmin(pmax(prob1, eps), 1 - eps)
y     <- as.numeric(truth) - 1           # factor {0,1} → 0/1
-mean(y * log(prob1) + (1 - y) * log(1 - prob1))
}
## Scale numeric columns in train & apply same transform to test
scale_like <- function(train_df, test_df, num_vars) {
means <- sapply(train_df[, ..num_vars], mean)
sds   <- sapply(train_df[, ..num_vars], sd)
train_df[, (num_vars) := Map(function(x, m, s) (x - m)/s,
.SD, means, sds),
.SDcols = num_vars]
test_df [, (num_vars) := Map(function(x, m, s) (x - m)/s,
.SD, means, sds),
.SDcols = num_vars]
list(train = train_df, test = test_df)
}
set.seed(42)  # global reproducibility
############################################################
## 1.  Load data --------------------------------------------------------
paths_train <- list(M = "out_data/scaled/usopen_subset_m_training.csv",
F = "out_data/scaled/usopen_subset_f_training.csv")
paths_test  <- list(M = "out_data/scaled/usopen_subset_m_testing.csv",
F = "out_data/scaled/usopen_subset_f_testing.csv")
train_list <- map(paths_train, ~ as.data.table(fread(.x))[Speed_MPH > 0])
test_list  <- map(paths_test,  ~ as.data.table(fread(.x))[Speed_MPH > 0])
############################################################
## 2.  Settings ---------------------------------------------------------
base_num   <- c("importance_z", "p_server_beats_returner_z", "ElapsedSeconds_fixed_z", "df_pct_server_z")
vars_fact <- c("ServeWidth", "ServeDepth")
## small tuning grid: hidden-units × weight-decay
grid_small <- expand_grid(
size  = c(3, 5, 7),
decay = c(0, 1e-4, 1e-3)
)
results <- list()   # will gather rows
############################################################
## 3.  Main loop --------------------------------------------------------
for (g in names(train_list)) {
train0 <- train_list[[g]]
test0  <- test_list [[g]]
for (serve in c(1, 2)) {
## filter first- or second-serves
train_sub <- train0[ServeNumber == serve]
test_sub  <- test0 [ServeNumber == serve]
## align factor levels
train_sub[, (vars_fact) := lapply(.SD, factor), .SDcols = vars_fact]
for (v in vars_fact)
test_sub[, (v) := factor(get(v), levels = levels(train_sub[[v]]))]
## ensure binary factor response
train_sub[, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
test_sub [, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
for (speed_var in c("Speed_MPH_z", "speed_ratio_z")) {
vars_num <- c(base_num, speed_var)
## modelling frames
train_dat <- train_sub[, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
test_dat  <- test_sub [, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
## numeric scaling
scaled <- scale_like(copy(train_dat), copy(test_dat), num_vars = vars_num)
train_scaled <- scaled$train
test_scaled  <- scaled$test
## ---- 3-fold CV on ≤10 000 rows ---------------------------------
n_tune   <- min(10000, nrow(train_scaled))
tune_idx <- sample(nrow(train_scaled), n_tune)
tune_dat <- train_scaled[tune_idx]
folds    <- cut(seq_len(n_tune), breaks = 3, labels = FALSE)
cv_scores <- grid_small %>% mutate(mean_ll = NA_real_)
for (grid_i in seq_len(nrow(grid_small))) {
s  <- grid_small$size [grid_i]
d  <- grid_small$decay[grid_i]
ll_vec <- numeric(3)
for (fold in 1:3) {
val_idx   <- which(folds == fold)
train_idx <- setdiff(seq_len(n_tune), val_idx)
nn_fit <- nnet(
serving_player_won ~ .,
data  = tune_dat[train_idx],
size  = s,
decay = d,
maxit = 200,
trace = FALSE
)
probs <- as.numeric(predict(nn_fit, tune_dat[val_idx], type = "raw"))
ll_vec[fold] <- fast_logloss(tune_dat$serving_player_won[val_idx], probs)
}
cv_scores$mean_ll[grid_i] <- mean(ll_vec)
}
best <- cv_scores %>% slice_min(mean_ll, n = 1)
## ---- Fit best model on full subset -----------------------------
nn_fit_final <- nnet(
serving_player_won ~ .,
data  = train_scaled,
size  = best$size,
decay = best$decay,
maxit = 500,
trace = FALSE
)
## ---- Evaluate on held-out test set -----------------------------
probs_test <- as.numeric(predict(nn_fit_final, test_scaled, type = "raw"))
pred_class <- factor(ifelse(probs_test >= 0.5, 1, 0), levels = c(0, 1))
acc <- mean(pred_class == test_scaled$serving_player_won)
ll  <- fast_logloss(test_scaled$serving_player_won, probs_test)
## ---- Record result ---------------------------------------------
results[[length(results) + 1]] <- list(
gender         = g,
serve_number   = serve,
speed_variable = speed_var,
hidden_size    = best$size,
weight_decay   = best$decay,
test_accuracy  = acc,
log_loss       = ll
)
}
}
}
############################################################
## 4.  Save + display results ------------------------------------------
results_df <- bind_rows(results) %>%
arrange(gender, serve_number, speed_variable)
print(results_df)
write.csv(results_df, "nn_results_usopen.csv", row.names = FALSE)
## Fast log-loss (binary)
fast_logloss <- function(truth, prob1, eps = 1e-15) {
prob1 <- pmin(pmax(prob1, eps), 1 - eps)
y     <- as.numeric(truth) - 1           # factor {0,1} → 0/1
-mean(y * log(prob1) + (1 - y) * log(1 - prob1))
}
## Scale numeric columns in train & apply same transform to test
scale_like <- function(train_df, test_df, num_vars) {
means <- sapply(train_df[, ..num_vars], mean)
sds   <- sapply(train_df[, ..num_vars], sd)
train_df[, (num_vars) := Map(function(x, m, s) (x - m)/s,
.SD, means, sds),
.SDcols = num_vars]
test_df [, (num_vars) := Map(function(x, m, s) (x - m)/s,
.SD, means, sds),
.SDcols = num_vars]
list(train = train_df, test = test_df)
}
set.seed(42)  # global reproducibility
############################################################
## 1.  Load data --------------------------------------------------------
paths_train <- list(M = "out_data/scaled/wimbledon_subset_m_training.csv",
F = "out_data/scaled/wimbledon_subset_f_training.csv")
paths_test  <- list(M = "out_data/scaled/wimbledon_subset_m_testing.csv",
F = "out_data/scaled/wimbledon_subset_f_testing.csv")
train_list <- map(paths_train, ~ as.data.table(fread(.x))[Speed_MPH > 0])
test_list  <- map(paths_test,  ~ as.data.table(fread(.x))[Speed_MPH > 0])
############################################################
## 2.  Settings ---------------------------------------------------------
base_num   <- c("importance_z", "p_server_beats_returner_z", "ElapsedSeconds_fixed_z", "df_pct_server_z")
vars_fact <- c("ServeWidth", "ServeDepth")
## small tuning grid: hidden-units × weight-decay
grid_small <- expand_grid(
size  = c(3, 5, 7),
decay = c(0, 1e-4, 1e-3)
)
results <- list()   # will gather rows
############################################################
## 3.  Main loop --------------------------------------------------------
for (g in names(train_list)) {
train0 <- train_list[[g]]
test0  <- test_list [[g]]
for (serve in c(1, 2)) {
## filter first- or second-serves
train_sub <- train0[ServeNumber == serve]
test_sub  <- test0 [ServeNumber == serve]
## align factor levels
train_sub[, (vars_fact) := lapply(.SD, factor), .SDcols = vars_fact]
for (v in vars_fact)
test_sub[, (v) := factor(get(v), levels = levels(train_sub[[v]]))]
## ensure binary factor response
train_sub[, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
test_sub [, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
for (speed_var in c("Speed_MPH_z", "speed_ratio_z")) {
vars_num <- c(base_num, speed_var)
## modelling frames
train_dat <- train_sub[, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
test_dat  <- test_sub [, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
## numeric scaling
scaled <- scale_like(copy(train_dat), copy(test_dat), num_vars = vars_num)
train_scaled <- scaled$train
test_scaled  <- scaled$test
## ---- 3-fold CV on ≤10 000 rows ---------------------------------
n_tune   <- min(10000, nrow(train_scaled))
tune_idx <- sample(nrow(train_scaled), n_tune)
tune_dat <- train_scaled[tune_idx]
folds    <- cut(seq_len(n_tune), breaks = 3, labels = FALSE)
cv_scores <- grid_small %>% mutate(mean_ll = NA_real_)
for (grid_i in seq_len(nrow(grid_small))) {
s  <- grid_small$size [grid_i]
d  <- grid_small$decay[grid_i]
ll_vec <- numeric(3)
for (fold in 1:3) {
val_idx   <- which(folds == fold)
train_idx <- setdiff(seq_len(n_tune), val_idx)
nn_fit <- nnet(
serving_player_won ~ .,
data  = tune_dat[train_idx],
size  = s,
decay = d,
maxit = 200,
trace = FALSE
)
probs <- as.numeric(predict(nn_fit, tune_dat[val_idx], type = "raw"))
ll_vec[fold] <- fast_logloss(tune_dat$serving_player_won[val_idx], probs)
}
cv_scores$mean_ll[grid_i] <- mean(ll_vec)
}
best <- cv_scores %>% slice_min(mean_ll, n = 1)
## ---- Fit best model on full subset -----------------------------
nn_fit_final <- nnet(
serving_player_won ~ .,
data  = train_scaled,
size  = best$size,
decay = best$decay,
maxit = 500,
trace = FALSE
)
## ---- Evaluate on held-out test set -----------------------------
probs_test <- as.numeric(predict(nn_fit_final, test_scaled, type = "raw"))
pred_class <- factor(ifelse(probs_test >= 0.5, 1, 0), levels = c(0, 1))
acc <- mean(pred_class == test_scaled$serving_player_won)
ll  <- fast_logloss(test_scaled$serving_player_won, probs_test)
## ---- Record result ---------------------------------------------
results[[length(results) + 1]] <- list(
gender         = g,
serve_number   = serve,
speed_variable = speed_var,
hidden_size    = best$size,
weight_decay   = best$decay,
test_accuracy  = acc,
log_loss       = ll
)
}
}
}
############################################################
## 4.  Save + display results ------------------------------------------
results_df <- bind_rows(results) %>%
arrange(gender, serve_number, speed_variable)
print(results_df)
write.csv(results_df, "nn_results_wimbledon.csv", row.names = FALSE)
fast_logloss <- function(truth, prob1, eps = 1e-15) {
prob1 <- pmin(pmax(prob1, eps), 1 - eps)
y     <- as.numeric(truth) - 1        # factor {0,1} → 0/1
-mean(y * log(prob1) + (1 - y) * log(1 - prob1))
}
scale_like <- function(train_df, test_df, num_vars) {
means <- sapply(train_df[, ..num_vars], mean)
sds   <- sapply(train_df[, ..num_vars], sd)
train_df[, (num_vars) := Map(function(x, m, s) (x - m)/s, .SD, means, sds),
.SDcols = num_vars]
test_df [, (num_vars) := Map(function(x, m, s) (x - m)/s, .SD, means, sds),
.SDcols = num_vars]
list(train = train_df, test = test_df)
}
## 1.  Load US-Open men data, drop Speed_MPH == 0 -----------------------------
path_train <- "out_data/scaled/usopen_subset_m_training.csv"  # 2021–24
path_test  <- "out_data/scaled/usopen_subset_m_testing.csv"   # 2018–19
train0 <- as.data.table(fread(path_train))[Speed_MPH > 0]
test0  <- as.data.table(fread(path_test ))[Speed_MPH > 0]
## 2.  Settings ---------------------------------------------------------------
base_num  <- c("importance_z",
"p_server_beats_returner_z",
"ElapsedSeconds_fixed_z",
"df_pct_server_z")
vars_fact <- c("ServeWidth", "ServeDepth")
grid_small <- expand_grid(
size  = c(3, 5, 7),
decay = c(0, 1e-4, 1e-3)
)
results <- list()
## 3.  Loop over serve number & speed variable --------------------------------
for (serve in c(1, 2)) {
train_sub <- train0[ServeNumber == serve]
test_sub  <- test0 [ServeNumber == serve]
## align factor levels
train_sub[, (vars_fact) := lapply(.SD, factor), .SDcols = vars_fact]
for (v in vars_fact)
test_sub[, (v) := factor(get(v), levels = levels(train_sub[[v]]))]
train_sub[, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
test_sub [, serving_player_won := factor(serving_player_won, levels = c(0, 1))]
for (speed_var in c("Speed_MPH_z", "speed_ratio_z")) {
vars_num <- c(base_num, speed_var)
train_dat <- train_sub[, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
test_dat  <- test_sub [, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
## numeric scaling -------------------------------------------------
scaled <- scale_like(copy(train_dat), copy(test_dat), num_vars = vars_num)
train_scaled <- scaled$train
test_scaled  <- scaled$test
## 3-fold CV on ≤10k rows -----------------------------------------
n_tune   <- min(10000, nrow(train_scaled))
tune_idx <- sample(nrow(train_scaled), n_tune)
tune_dat <- train_scaled[tune_idx]
folds    <- cut(seq_len(n_tune), breaks = 3, labels = FALSE)
cv_scores <- grid_small %>% mutate(mean_ll = NA_real_)
for (i in seq_len(nrow(grid_small))) {
s <- grid_small$size [i]
d <- grid_small$decay[i]
ll_vec <- numeric(3)
for (fold in 1:3) {
val_idx   <- which(folds == fold)
train_idx <- setdiff(seq_len(n_tune), val_idx)
nn_fit <- nnet(
serving_player_won ~ .,
data  = tune_dat[train_idx],
size  = s,
decay = d,
maxit = 200,
trace = FALSE
)
probs <- as.numeric(predict(nn_fit, tune_dat[val_idx], type = "raw"))
ll_vec[fold] <- fast_logloss(tune_dat$serving_player_won[val_idx], probs)
}
cv_scores$mean_ll[i] <- mean(ll_vec)
}
best <- cv_scores %>% slice_min(mean_ll, n = 1)
## Fit best model on full subset ----------------------------------
nn_fit_final <- nnet(
serving_player_won ~ .,
data  = train_scaled,
size  = best$size,
decay = best$decay,
maxit = 500,
trace = FALSE
)
## Evaluate on held-out test set ----------------------------------
probs_test <- as.numeric(predict(nn_fit_final, test_scaled, type = "raw"))
pred_class <- factor(ifelse(probs_test >= 0.5, 1, 0), levels = c(0, 1))
acc <- mean(pred_class == test_scaled$serving_player_won)
ll  <- fast_logloss(test_scaled$serving_player_won, probs_test)
## Record result ---------------------------------------------------
results[[length(results) + 1]] <- list(
serve_number   = serve,
speed_variable = speed_var,
hidden_size    = best$size,
weight_decay   = best$decay,
test_accuracy  = acc,
log_loss       = ll
)
}
}
## 4.  Save + display results -------------------------------------------------
results_df <- bind_rows(results) %>%
arrange(serve_number, speed_variable)
print(results_df)
write.csv(results_df, "nn_results_usopen_m.csv", row.names = FALSE)
for (speed_var in c("Speed_MPH_z", "speed_ratio_z")) {
vars_num <- c(base_num, speed_var)
train_dat <- train_sub[, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
test_dat  <- test_sub [, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
## ---- NEW: remove rows with *any* NA --------------------------------
train_dat <- train_dat[complete.cases(train_dat)]
test_dat  <- test_dat [complete.cases(test_dat)]
## If everything vanished, skip this combo
if (nrow(train_dat) == 0 || nrow(test_dat) == 0) next
## numeric scaling ----------------------------------------------------
scaled <- scale_like(copy(train_dat), copy(test_dat), num_vars = vars_num)
train_scaled <- scaled$train
test_scaled  <- scaled$test
## ---- [CV tuning block unchanged] -----------------------------------
## … 3-fold CV to pick (size, decay) …
## Fit best model on full subset --------------------------------------
nn_fit_final <- nnet(
serving_player_won ~ .,
data  = train_scaled,
size  = best$size,
decay = best$decay,
maxit = 500,
trace = FALSE
)
## Evaluate on held-out test set --------------------------------------
probs_test <- as.numeric(predict(nn_fit_final, test_scaled, type = "raw"))
keep <- !is.na(probs_test)                         # just in case
probs_test <- probs_test[keep]
truth      <- test_scaled$serving_player_won[keep]
if (length(truth) == 0) next                      # no usable rows
pred_class <- factor(ifelse(probs_test >= 0.5, 1, 0), levels = c(0, 1))
acc <- mean(pred_class == truth)
ll  <- fast_logloss(truth, probs_test)
## Record result -------------------------------------------------------
results[[length(results) + 1]] <- list(
serve_number   = serve,
speed_variable = speed_var,
hidden_size    = best$size,
weight_decay   = best$decay,
test_accuracy  = acc,
log_loss       = ll
)
}
## 4.  Save + display results -------------------------------------------------
results_df <- bind_rows(results) %>%
arrange(serve_number, speed_variable)
print(results_df)
## 3.  Loop over serve number & speed variable --------------------------------
for (speed_var in c("Speed_MPH_z", "speed_ratio_z")) {
vars_num <- c(base_num, speed_var)
train_dat <- train_sub[, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
test_dat  <- test_sub [, c(vars_num, vars_fact, "serving_player_won"), with = FALSE]
## ---- NEW: remove rows with *any* NA --------------------------------
train_dat <- train_dat[complete.cases(train_dat)]
test_dat  <- test_dat [complete.cases(test_dat)]
## If everything vanished, skip this combo
if (nrow(train_dat) == 0 || nrow(test_dat) == 0) next
## numeric scaling ----------------------------------------------------
scaled <- scale_like(copy(train_dat), copy(test_dat), num_vars = vars_num)
train_scaled <- scaled$train
test_scaled  <- scaled$test
## ---- [CV tuning block unchanged] -----------------------------------
## … 3-fold CV to pick (size, decay) …
## Fit best model on full subset --------------------------------------
nn_fit_final <- nnet(
serving_player_won ~ .,
data  = train_scaled,
size  = best$size,
decay = best$decay,
maxit = 500,
trace = FALSE
)
## Evaluate on held-out test set --------------------------------------
probs_test <- as.numeric(predict(nn_fit_final, test_scaled, type = "raw"))
keep <- !is.na(probs_test)                         # just in case
probs_test <- probs_test[keep]
truth      <- test_scaled$serving_player_won[keep]
if (length(truth) == 0) next                      # no usable rows
pred_class <- factor(ifelse(probs_test >= 0.5, 1, 0), levels = c(0, 1))
acc <- mean(pred_class == truth)
ll  <- fast_logloss(truth, probs_test)
## Record result -------------------------------------------------------
results[[length(results) + 1]] <- list(
serve_number   = serve,
speed_variable = speed_var,
hidden_size    = best$size,
weight_decay   = best$decay,
test_accuracy  = acc,
log_loss       = ll
)
}
## 4.  Save + display results -------------------------------------------------
results_df <- bind_rows(results) %>%
arrange(serve_number, speed_variable)
print(results_df)
